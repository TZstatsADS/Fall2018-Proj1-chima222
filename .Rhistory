filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period, months_3 = "3m", hours_24 = "24h"))
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
View(hm_data)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
cleaned_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period, months_3 = "3m", hours_24 = "24h"))
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = cleaned_hm,
group_column = parenthood,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = reflection_period,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = age,
group_column = reflection_period,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = martial,
group_column = reflection_period,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = martial,
group_column = reflection_period,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = age,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = marital,
plot = TRUE)
freq[freq$word =="mth",]
freq[freq$word =="deadlift",]
# get just the tf-idf output for the hotel topics
reviews_tfidf_byage <- top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group = age,
plot = F)
# do our own plotting
reviews_tfidf_byage  %>%
group_by(age) %>%
top_n(5) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = age)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~age, ncol = 4, scales = "free", ) +
coord_flip()
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
# name for the column we're going to unnest_tokens_ to
# (you only need to worry about enquo stuff if you're
# writing a function using using tidyverse packages)
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
# (this is due to funkiness with calling ggplot2
# in functions)
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
# name for the column we're going to unnest_tokens_ to
# (you only need to worry about enquo stuff if you're
# writing a function using using tidyverse packages)
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
# (this is due to funkiness with calling ggplot2
# in functions)
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = marital,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = gender,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
unnest_tokens
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
# name for the column we're going to unnest_tokens_ to
# (you only need to worry about enquo stuff if you're
# writing a function using using tidyverse packages)
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
ungroup(count(!!group_column, word))
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
# (this is due to funkiness with calling ggplot2
# in functions)
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
# name for the column we're going to unnest_tokens_ to
# (you only need to worry about enquo stuff if you're
# writing a function using using tidyverse packages)
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
# (this is due to funkiness with calling ggplot2
# in functions)
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
#I am creating a function that can do suprevised modeling using TF-IDF("term frequency-inverse document frequency") method. TF-IDF can help identify words that are common in specifict documents(we assume they are important) and words that are common in all documents(we assume words that show in all documents aren't important).
#The function takes in a dataframe, the name of the column that has the texts and the name of the column that has the topic labels(gender,marital etc.)in it.
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <-  ungroup(count(!!group_column, word,unnest_tokens(word, !!text_column,text_df)))
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
?summarize
#I am creating a function that can do suprevised modeling using TF-IDF("term frequency-inverse document frequency") method. TF-IDF can help identify words that are common in specifict documents(we assume they are important) and words that are common in all documents(we assume words that shows in all documents aren't important).
#The function takes in a dataframe, the name of the column that has the texts and the name of the column that has the topic labels(gender,marital etc.)in it.
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <-
summarize(total = sum(n),group_by(words!!group_column))
#I am creating a function that can do suprevised modeling using TF-IDF("term frequency-inverse document frequency") method. TF-IDF can help identify words that are common in specifict documents(we assume they are important) and words that are common in all documents(we assume words that shows in all documents aren't important).
#The function takes in a dataframe, the name of the column that has the texts and the name of the column that has the topic labels(gender,marital etc.)in it.
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <-summarize(total = sum(n),group_by(words!!group_column))
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
#I am creating a function that can do suprevised modeling using TF-IDF("term frequency-inverse document frequency") method. TF-IDF can help identify words that are common in specifict documents(we assume they are important) and words that are common in all documents(we assume words that shows in all documents aren't important).
#The function takes in a dataframe, the name of the column that has the texts and the name of the column that has the topic labels(gender,marital etc.)in it.
top_terms_by_topic_tfidf <- function(text_df, text_column, group_column, plot = T){
group_column <- enquo(group_column)
text_column <- enquo(text_column)
# get the count of each word in each review
words <- text_df %>%
unnest_tokens(word, !!text_column) %>%
count(!!group_column, word) %>%
ungroup()
# get the number of words per text
total_words <- words %>%
group_by(!!group_column) %>%
summarize(total = sum(n))
# combine the two dataframes we just made
words <- left_join(words, total_words)
# get the tf_idf & order the words by degree of relevence
tf_idf <- words %>%
bind_tf_idf(word, !!group_column, n) %>%
select(-total) %>%
arrange(desc(tf_idf)) %>%
mutate(word = factor(word, levels = rev(unique(word))))
if(plot == T){
# convert "group" into a quote of a name
group_name <- quo_name(group_column)
tf_idf %>%
group_by(!!group_column) %>%
top_n(10) %>%
ungroup %>%
ggplot(aes(word, tf_idf, fill = as.factor(group_name))) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(reformulate(group_name), scales = "free") +
coord_flip()
}else{
# return the entire tf_idf dataframe
return(tf_idf)
}
}
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = marital,
plot = TRUE)
hm_data$cleaned_hm == "thekkady"
sum(hm_data$original_hm =="thekkady")
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = gender,
plot = TRUE)
View(hm_data)
top_terms_by_topic_tfidf(text_df = hm_data,
text_column = text,
group_column = parenthood,
plot = TRUE)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(d3heatmap)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(NLP)
library(openNLP)
install.packages("openNLP")
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(NLP)
library(openNLP)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(NLP)
library(openNLP)
install.packages("openNLP")
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(NLP)
library(openNLP)
install.packages("NLP")
NumOfVerbs=sapply(strsplit(as.character(tagPOS(hm_data$cleaned_hm)),"[[:punct:]]*/VB.?"),function(x) {res = sub("(^.*\\s)(\\w+$)", "\\2", x); res[!grepl("\\s",res)]} )
library(openNLP)
install.packages("rJava", type = "source")
install.packages("openNLP")
library(openNLP)
require(rJava)
tagPOS <-  function(x, ...) {
s <- as.String(x)
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- Annotation(1L, "sentence", 1L, nchar(s))
a2 <- annotate(s, word_token_annotator, a2)
a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
a3w <- a3[a3$type == "word"]
POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
list(POStagged = POStagged, POStags = POStags)
}
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(dplyr)
library(tm)
library(ggplot2)
library(topicmodels)
library(SnowballC)
library(NLP)
NumOfVerbs=sapply(strsplit(as.character(tagPOS(hm_data$cleaned_hm)),"[[:punct:]]*/VB.?"),function(x) {res = sub("(^.*\\s)(\\w+$)", "\\2", x); res[!grepl("\\s",res)]} )
View(top_terms_by_topic_tfidf)
View(tagPOS)
library(openNLP)
